# üß† Vulngard

Ce projet repose sur **Ollama** et le mod√®le **deepseek-coder:6.7b** pour la d√©tection de code vuln√©rable dans des projets OpenSource en se basant uniquement sur la description des CVE.

---

## üöÄ Installation rapide

### 1. Installer Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

V√©rifiez l'installation :

```bash
ollama --version
```

---

### 2. T√©l√©charger le mod√®le `deepseek-coder:6.7b`

```bash
ollama pull deepseek-coder:6.7b
```

---

### 3. Cloner ce d√©p√¥t et cr√©er le mod√®le personnalis√©

```bash
git clone git@github.com:nwOLXTYv/VulnGuard.git
cd VulnGuard
```

> Le fichier `Modelfile` est d√©j√† pr√©sent dans ce d√©p√¥t.

Cr√©ez votre mod√®le :

```bash
ollama create Michel -f ./Modelfile
```

---

### 4. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

---

## üõ†Ô∏è Utilisation du script VulnGuard

VulnGuard est un outil d'analyse de vuln√©rabilit√©s qui utilise les mod√®les Ollama pour √©valuer les vuln√©rabilit√©s de code. Voici comment l'utiliser :

### Ex√©cution du script

```bash
python3 vulnguard.py
```

### Fonctionnement pas √† pas

1. **S√©lection du mod√®le** : Le script liste automatiquement les mod√®les Ollama disponibles sur votre syst√®me.
   - Par d√©faut, il utilise `Michel` s'il est disponible
   - Vous pouvez s√©lectionner un autre mod√®le par son num√©ro ou son nom

2. **Saisie des informations** :
   - Description de la CVE (Common Vulnerabilities and Exposures)
   - Emplacement du fichier concern√©
   - Code diff √† analyser (termin√© par une ligne contenant uniquement "END")

3. **Analyse de la vuln√©rabilit√©** : Le script envoie ces informations au mod√®le Ollama s√©lectionn√©

4. **Affichage des r√©sultats** : L'analyse est pr√©sent√©e sous forme de rapport d√©taill√©

---

## üß† Pourquoi `deepseek-coder:6.7b` ?

Nous avons test√© plusieurs mod√®les avec diff√©rentes tailles (nombre de n≈ìuds) pour trouver le **meilleur compromis entre qualit√© et rapidit√©**.

- `deepseek-coder:6.7b` a montr√© d'excellents r√©sultats
- Fonctionne bien sur une carte graphique 16 Go (ex: AMD RX 7800XT)

üìå Si vous souhaitez explorer d'autres mod√®les, visitez :

üëâ [https://ollama.com/search](https://ollama.com/search)

Modifiez simplement la ligne `FROM` du `Modelfile`, par exemple :

```Dockerfile
FROM mistral:7b
```

> üí° Le suffixe `:6.7b`, `:34b`, etc. correspond au **nombre de n≈ìuds**.  
> Plus il est √©lev√©, meilleures sont les performances... mais plus la g√©n√©ration est lente.

---

## üì¥ Fonctionnement hors ligne

Une fois le mod√®le t√©l√©charg√©, **aucune connexion internet n'est requise**. Le LLM tourne enti√®rement en **local**, sans cloud.

---

## üîß Configuration avanc√©e

### Template de prompt personnalis√©

Par d√©faut, le script utilise un template situ√© dans `./llm/user-prompt.txt`. Vous pouvez cr√©er votre propre template avec les variables suivantes :
- `{{CVE_DESCRIPTION}}` : Description de la CVE
- `{{File_Location}}` : Emplacement du fichier
- `{{DIFF_HUNK}}` : Code diff √† analyser

---

## üìã Commandes utiles

| Description                      | Commande                                         |
|----------------------------------|--------------------------------------------------|
| Installer Ollama                 | `curl -fsSL https://ollama.com/install.sh \| sh` |
| T√©l√©charger un mod√®le            | `ollama pull <model_name>`                       |
| Quitter le prompt                | `/bye`                                           |
| Cr√©er un mod√®le personnalis√©     | `ollama create Michel -f ./Modelfile`            |
| Lancer le mod√®le personnalis√©    | `ollama run Michel`                              |
| Voir les mod√®les install√©s       | `ollama list`                                    |
| Lancer VulnGuard                 | `python3 vulnguard.py`                           |

---

## üßë‚Äçüíª Contributeurs

- TAHRI Bahaaeddine
- MOREL Mathilde
- GOSSET Arthur