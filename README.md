# üß† Vulnerability Detector ‚Äì LLM Powered by Ollama & DeepSeek

Ce projet repose sur **Ollama** et le mod√®le **deepseek-coder:6.7b** pour la d√©tection de code vuln√©rable dans des projets OpenSource en se basant uniquement sur la description des CVE.

---

## üöÄ Installation rapide

### 1. Installer Ollama

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

V√©rifiez l‚Äôinstallation :

```bash
ollama --version
```

---

### 2. T√©l√©charger le mod√®le `deepseek-coder:6.7b`

```bash
ollama run deepseek-coder:6.7b
```

> üì• Cela d√©clenchera le t√©l√©chargement du mod√®le. Une fois termin√©, vous serez dans le prompt interactif.

Quittez le prompt avec :

```bash
/bye
```

---

### 3. Cloner ce d√©p√¥t et cr√©er le mod√®le personnalis√©

```bash
git clone https://votre-repo-git-url.git
cd votre-repo-git-folder
```

> Le fichier `Modelfile` est d√©j√† pr√©sent dans ce d√©p√¥t.

Cr√©ez votre mod√®le :

```bash
ollama create Michel -f ./Modelfile
```

---

### 4. Utiliser le mod√®le personnalis√©

```bash
ollama run Michel
```

> ‚ùå Quittez la session avec `/bye`

---

## üîç √Ä propos du `Modelfile`

Le `Modelfile` d√©finit comment le mod√®le est construit. Il permet :

- De partir d‚Äôun mod√®le existant (`FROM`)
- D'ajouter un comportement sp√©cifique (`SYSTEM`)

Exemple :

```Dockerfile
FROM deepseek-coder:6.7b
SYSTEM "You are a vulnerability detection assistant. Analyze code for security issues."
```

---

## üß† Pourquoi `deepseek-coder:6.7b` ?

Nous avons test√© plusieurs mod√®les avec diff√©rentes tailles (nombre de n≈ìuds) pour trouver le **meilleur compromis entre qualit√© et rapidit√©**.

- `deepseek-coder:6.7b` a montr√© d'excellents r√©sultats
- Fonctionne bien sur une carte graphique 16 Go (ex: AMD RX 7800XT)

üìå Si vous souhaitez explorer d'autres mod√®les, visitez :

üëâ [https://ollama.com/search](https://ollama.com/search)

Modifiez simplement la ligne `FROM` du `Modelfile`, par exemple :

```Dockerfile
FROM mistral:7b
```

> üí° Le suffixe `:6.7b`, `:34b`, etc. correspond au **nombre de n≈ìuds**.  
> Plus il est √©lev√©, meilleures sont les performances... mais plus la g√©n√©ration est lente.

---

## üì¥ Fonctionnement hors ligne

Une fois le mod√®le t√©l√©charg√©, **aucune connexion internet n‚Äôest requise**. Le LLM tourne enti√®rement en **local**, sans cloud.

---

## üìã Commandes utiles

| Description                      | Commande                                        |
|----------------------------------|-------------------------------------------------|
| Installer Ollama                 | `curl -fsSL https://ollama.com/install.sh \| sh` |
| T√©l√©charger un mod√®le            | `ollama run deepseek-coder:6.7b`               |
| Quitter le prompt                | `/bye`                                          |
| Cr√©er un mod√®le personnalis√©     | `ollama create vulnerability_detector -f ./Modelfile` |
| Lancer le mod√®le personnalis√©    | `ollama run vulnerability_detector`            |
| Voir les mod√®les install√©s       | `ollama list`                                   |

---

## üßë‚Äçüíª Contributeurs

- TAHRI Bahaaeddine
- MOREL Mathilde
- GOSSET Arthur
